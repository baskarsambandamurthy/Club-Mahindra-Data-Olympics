{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.52 s, sys: 288 ms, total: 3.8 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PATH=\"../input/\"\n",
    "train = pd.read_csv(PATH+\"train.csv\")\n",
    "test = pd.read_csv(PATH+\"test.csv\")\n",
    "subm_df = pd.read_csv(PATH+\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetcol = 'amount_spent_per_room_night_scaled'\n",
    "target = train[targetcol]\n",
    "# del train[targetcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_id</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>checkout_date</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>main_product_code</th>\n",
       "      <th>numberofadults</th>\n",
       "      <th>numberofchildren</th>\n",
       "      <th>persontravellingid</th>\n",
       "      <th>resort_region_code</th>\n",
       "      <th>resort_type_code</th>\n",
       "      <th>room_type_booked_code</th>\n",
       "      <th>roomnights</th>\n",
       "      <th>season_holidayed_code</th>\n",
       "      <th>state_code_residence</th>\n",
       "      <th>state_code_resort</th>\n",
       "      <th>total_pax</th>\n",
       "      <th>member_age_buckets</th>\n",
       "      <th>booking_type_code</th>\n",
       "      <th>memberid</th>\n",
       "      <th>cluster_code</th>\n",
       "      <th>reservationstatusid_code</th>\n",
       "      <th>resort_id</th>\n",
       "      <th>amount_spent_per_room_night_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07659f3758d8aee27f5a7e2887adeacb67021cb95ada1b...</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...</td>\n",
       "      <td>7.706428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03930f033646d073462b35d411616323597715ac4fc398...</td>\n",
       "      <td>23/01/15</td>\n",
       "      <td>11/04/15</td>\n",
       "      <td>16/04/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>39fa9ec190eee7b6f4dff1100d6343e10918d044c75eac...</td>\n",
       "      <td>6.662563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d145a32920e6587ad95bfe299d80c0affa268220535aaf...</td>\n",
       "      <td>28/01/15</td>\n",
       "      <td>01/02/15</td>\n",
       "      <td>05/02/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>535fa30d7e25dd8a49f1536779734ec8286108d115da50...</td>\n",
       "      <td>7.871602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cfd77f44811ed62f25a220b53324cdbafc662a4c9e5f04...</td>\n",
       "      <td>02/05/15</td>\n",
       "      <td>11/06/15</td>\n",
       "      <td>16/06/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>5.344943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>937cff9e4dcfc2459620153dfc8b9962ac22bea67dfb29...</td>\n",
       "      <td>02/09/15</td>\n",
       "      <td>14/12/15</td>\n",
       "      <td>19/12/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>7.059346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      reservation_id                ...                 amount_spent_per_room_night_scaled\n",
       "0  07659f3758d8aee27f5a7e2887adeacb67021cb95ada1b...                ...                                           7.706428\n",
       "1  03930f033646d073462b35d411616323597715ac4fc398...                ...                                           6.662563\n",
       "2  d145a32920e6587ad95bfe299d80c0affa268220535aaf...                ...                                           7.871602\n",
       "3  cfd77f44811ed62f25a220b53324cdbafc662a4c9e5f04...                ...                                           5.344943\n",
       "4  937cff9e4dcfc2459620153dfc8b9962ac22bea67dfb29...                ...                                           7.059346\n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# train['booking_date'].dtype.name=='object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "def preprocdate(data,coltemplate):\n",
    "    col = coltemplate+'_date'\n",
    "    \n",
    "    if   data[col].dtype.name=='object':\n",
    "        print('Date type conversion start')\n",
    "        data[col]=pd.to_datetime(data[col],format='%d/%m/%y')\n",
    "        print('Date type conversion complete')\n",
    "       \n",
    "#     data[col]=pd.to_datetime(data[col],infer_datetime_format=True)\n",
    "    data[coltemplate+'_month']=data[col].dt.month\n",
    "    data[coltemplate+'_year']=data[col].dt.year\n",
    "#     data[coltemplate+'_day']=data[col].dt.day\n",
    "    data[coltemplate+'_dayofweek']=data[col].dt.dayofweek\n",
    "    data[coltemplate+'_weekend'] = (data[coltemplate+'_dayofweek'] >= 5).astype('int')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def onehotenc(data,cols):\n",
    "    onehot_encoder = OneHotEncoder(sparse=False,categories='auto',n_values='auto',\n",
    "                                  categorical_features='all')\n",
    "    onehot_encoded = onehot_encoder.fit_transform(data[cols])\n",
    "\n",
    "    enc_feats = onehot_encoder.get_feature_names(input_features=cols)\n",
    "    \n",
    "    for i,col in enumerate(enc_feats):\n",
    "        data[col] = onehot_encoded[:,i]\n",
    "    \n",
    "    return data\n",
    "    \n",
    "#factorize string data\n",
    "def preproc(train,test):\n",
    "    \n",
    "    train['istrain']=1\n",
    "    test['istrain']=0\n",
    "    combined = pd.concat([train,test])\n",
    "    \n",
    "    fact_cols = ['member_age_buckets','cluster_code','reservationstatusid_code','resort_id']\n",
    "    \n",
    "    print('Factorize Start...')\n",
    "    for col in fact_cols:\n",
    "        print('col:',col)\n",
    "        combined[col],indexer=pd.factorize(combined[col])\n",
    "    \n",
    "#     date_cols = ['checkin_date','checkout_date','booking_date']\n",
    "    print('Date Preproc Start...')\n",
    "    date_cols = ['checkin','checkout','booking']\n",
    "    for col in date_cols:\n",
    "        print('col:',col)\n",
    "        combined = preprocdate(combined,col)\n",
    "    \n",
    "    #replace NaN with -1\n",
    "#     nan_cols = ['season_holidayed_code']\n",
    "#     for col in nan_cols:\n",
    "#         combined[col].fillna(-1,inplace=True)\n",
    "    \n",
    "#     ohe_cols =['channel_code','main_product_code','resort_region_code',\n",
    "#               'resort_type_code','room_type_booked_code','season_holidayed_code',\n",
    "#               'member_age_buckets','cluster_code','reservationstatusid_code']\n",
    "#     combined = onehotenc(combined,ohe_cols)\n",
    "    \n",
    "    train = combined[combined['istrain']==1]\n",
    "    test = combined[combined['istrain']==0]\n",
    "    \n",
    "    del train['istrain'],test['istrain'], combined; gc.collect()\n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorize Start...\n",
      "col: member_age_buckets\n",
      "col: cluster_code\n",
      "col: reservationstatusid_code\n",
      "col: resort_id\n",
      "Date Preproc Start...\n",
      "col: checkin\n",
      "Date type conversion start\n",
      "Date type conversion complete\n",
      "col: checkout\n",
      "Date type conversion start\n",
      "Date type conversion complete\n",
      "col: booking\n",
      "Date type conversion start\n",
      "Date type conversion complete\n"
     ]
    }
   ],
   "source": [
    "train,test=preproc(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getenccolname(colname,cols_agg):\n",
    "    if 'var' in cols_agg:\n",
    "        colname =\"targetvarenc_\"+colname\n",
    "    elif 'std' in cols_agg:\n",
    "        colname =\"targetstdenc_\"+colname \n",
    "    elif 'sum' in cols_agg:   \n",
    "        colname =\"targetsumenc_\"+colname\n",
    "    elif 'min' in cols_agg:   \n",
    "        colname =\"targetminenc_\"+colname\n",
    "    elif 'max' in cols_agg:   \n",
    "        colname =\"targetmaxenc_\"+colname\n",
    "    elif 'median' in cols_agg:   \n",
    "        colname =\"targetmedianenc_\"+colname\n",
    "    elif 'count' in cols_agg:   \n",
    "        colname =\"targetcountenc_\"+colname\n",
    "    elif 'iqmean' in cols_agg:   \n",
    "        colname =\"targetiqmeanenc_\"+colname\n",
    "    else:\n",
    "        colname =\"targetenc_\"+colname\n",
    "        \n",
    "    return colname\n",
    "\n",
    "def droptargetenccols(train, val,test):\n",
    "     #remove target encoding fields if present\n",
    "    targetenccols = [col for col in train.columns if ('targetenc' in col) or ('targetstdenc' in col)]\n",
    "    train.drop(targetenccols,axis=1,inplace=True)\n",
    "    val.drop(targetenccols,axis=1,inplace=True)\n",
    "    targetenccols_test = [col for col in test.columns if ('targetenc' in col) or ('targetstdenc' in col)]\n",
    "    test.drop(targetenccols_test,axis=1,inplace=True)\n",
    "    \n",
    "    return train, val,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_coding(data, feature, target, n_folds=20, n_inner_folds=10):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    impact_coded = pd.Series()\n",
    "        \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=8888) \n",
    "    oof_mean_cv = pd.DataFrame()\n",
    "    split = 0\n",
    "    print('col:',feature)\n",
    "#     print()\n",
    "    for outer_, (infold, oof) in enumerate(kf.split(data[feature], data[target])):\n",
    "#         print('outer fold:{0} '.format(outer_))\n",
    "\n",
    "        kf_inner = KFold(n_splits=n_inner_folds, shuffle=True, random_state=8888)\n",
    "        inner_split = 0\n",
    "        inner_oof_mean_cv = pd.DataFrame()\n",
    "        oof_default_inner_mean = data.iloc[infold][target].mean()\n",
    "        \n",
    "        tr_outer = data.iloc[infold]\n",
    "        \n",
    "        for inner_,(infold_inner, oof_inner) in enumerate(kf_inner.split(data.iloc[infold], data.loc[infold, target])):\n",
    "                    \n",
    "            # The mean to apply to the inner oof split (a 1/n_folds % based on the rest)\n",
    "#             oof_mean = data.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "            oof_mean = tr_outer.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "            \n",
    "            # Also populate mapping (this has all group -> mean for all inner CV folds)\n",
    "            inner_oof_mean_cv = inner_oof_mean_cv.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')\n",
    "            inner_oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True)\n",
    "            inner_split += 1\n",
    "\n",
    "        # compute mean for each value of categorical value across oof iterations\n",
    "        inner_oof_mean_cv_map = inner_oof_mean_cv.mean(axis=1)\n",
    "\n",
    "        # Also populate mapping\n",
    "        oof_mean_cv = oof_mean_cv.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')\n",
    "        oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True) # <- local mean as default\n",
    "        split += 1\n",
    "\n",
    "        feature_mean = data.loc[oof, feature].map(inner_oof_mean_cv_map).fillna(oof_default_inner_mean)\n",
    "        impact_coded = impact_coded.append(feature_mean)\n",
    "    \n",
    "    oof_default_mean = data[target].mean() # Gobal mean to use by default (you could further tune this)\n",
    "    return impact_coded, oof_mean_cv.mean(axis=1), oof_default_mean\n",
    "\n",
    "\n",
    "\n",
    "def encode_target_cv(tr, val, test, targetcolname, categ_variables, impact_coder=impact_coding,\n",
    "                    n_folds=20, n_inner_folds=10):\n",
    "    \"\"\"Apply original function for each <categ_variables> in  <data>\n",
    "    Reduced number of validation folds\n",
    "    \"\"\"\n",
    "    train_target = tr.copy() \n",
    "    \n",
    "    code_map = dict()\n",
    "    default_map = dict()\n",
    "    for f in categ_variables:\n",
    "        enccol_mean = getenccolname(f,'mean')\n",
    "        train_target.loc[:, enccol_mean], code_map[f], default_map[f] = impact_coder(train_target, f, \n",
    "                                                                                     targetcolname,\n",
    "                                                                                    n_folds=n_folds, \n",
    "                                                                                     n_inner_folds=n_inner_folds)\n",
    "        val.loc[:, enccol_mean] = val[f].map(code_map[f]).fillna(default_map[f])\n",
    "        test.loc[:, enccol_mean] = test[f].map(code_map[f]).fillna(default_map[f])\n",
    "        \n",
    "        \n",
    "#     return train_target, code_map, default_map\n",
    "    return train_target,val,test\n",
    "\n",
    "\n",
    "def impact_coding(data, feature, target, n_folds=20, n_inner_folds=10):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    impact_coded = pd.Series()\n",
    "        \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=8888) \n",
    "    oof_mean_cv = pd.DataFrame()\n",
    "    split = 0\n",
    "    print('col:',feature)\n",
    "#     print()\n",
    "    for outer_, (infold, oof) in enumerate(kf.split(data[feature], data[target])):\n",
    "#         print('outer fold:{0} '.format(outer_))\n",
    "\n",
    "        kf_inner = KFold(n_splits=n_inner_folds, shuffle=True, random_state=8888)\n",
    "        inner_split = 0\n",
    "        inner_oof_mean_cv = pd.DataFrame()\n",
    "        oof_default_inner_mean = data.iloc[infold][target].mean()\n",
    "        \n",
    "        tr_outer = data.iloc[infold]\n",
    "        \n",
    "        for inner_,(infold_inner, oof_inner) in enumerate(kf_inner.split(data.iloc[infold], data.loc[infold, target])):\n",
    "                    \n",
    "            # The mean to apply to the inner oof split (a 1/n_folds % based on the rest)\n",
    "#             oof_mean = data.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "            oof_mean = tr_outer.iloc[infold_inner].groupby(by=feature)[target].mean()\n",
    "            \n",
    "            # Also populate mapping (this has all group -> mean for all inner CV folds)\n",
    "            inner_oof_mean_cv = inner_oof_mean_cv.join(pd.DataFrame(oof_mean), rsuffix=inner_split, how='outer')\n",
    "            inner_oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True)\n",
    "            inner_split += 1\n",
    "\n",
    "        # compute mean for each value of categorical value across oof iterations\n",
    "        inner_oof_mean_cv_map = inner_oof_mean_cv.mean(axis=1)\n",
    "\n",
    "        # Also populate mapping\n",
    "        oof_mean_cv = oof_mean_cv.join(pd.DataFrame(inner_oof_mean_cv), rsuffix=split, how='outer')\n",
    "        oof_mean_cv.fillna(value=oof_default_inner_mean, inplace=True) # <- local mean as default\n",
    "        split += 1\n",
    "\n",
    "        feature_mean = data.loc[oof, feature].map(inner_oof_mean_cv_map).fillna(oof_default_inner_mean)\n",
    "        impact_coded = impact_coded.append(feature_mean)\n",
    "    \n",
    "    oof_default_mean = data[target].mean() # Gobal mean to use by default (you could further tune this)\n",
    "    return impact_coded, oof_mean_cv.mean(axis=1), oof_default_mean\n",
    "\n",
    "\n",
    "\n",
    "def encode_target_cv_group(tr, val, test, targetcolname, categ_variables, impact_coder=impact_coding,\n",
    "                    n_folds=20, n_inner_folds=10):\n",
    "    \"\"\"Apply original function for each <categ_variables> in  <data>\n",
    "    Reduced number of validation folds\n",
    "    \"\"\"\n",
    "    train_target = tr.copy() \n",
    "    \n",
    "    code_map = dict()\n",
    "    default_map = dict()\n",
    "    for f in categ_variables:\n",
    "        enccol_mean = 'targetenc_groupmean'\n",
    "        train_target.loc[:, enccol_mean], code_map[f], default_map[f] = impact_coder(train_target, categ_variables, \n",
    "                                                                                     targetcolname,\n",
    "                                                                                    n_folds=n_folds, \n",
    "                                                                                     n_inner_folds=n_inner_folds)\n",
    "        val.loc[:, enccol_mean] = val[f].map(code_map[f]).fillna(default_map[f])\n",
    "        test.loc[:, enccol_mean] = test[f].map(code_map[f]).fillna(default_map[f])\n",
    "        \n",
    "        \n",
    "#     return train_target, code_map, default_map\n",
    "    return train_target,val,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_targetencode(train,target,test,n_splits,catcolnames,targetcol):\n",
    "#                     ,smoothing,min_samples_leaf,noise_level):\n",
    "\n",
    "    start = time.time()\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=4590)\n",
    "    indices = folds.split(train.values, target.values)\n",
    "\n",
    "    test_index = test.index\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(indices):\n",
    "        print('******************************************************')\n",
    "        print(\"FOLD  ---  {}\".format(fold_))\n",
    "        print('******************************************************')\n",
    "\n",
    "        tr = train.iloc[trn_idx]\n",
    "        val = train.iloc[val_idx]\n",
    "        \n",
    "        tr_index = tr.index\n",
    "        val_index = val.index\n",
    "        #drop any existing target enc cols\n",
    "        tr,val,test = droptargetenccols(tr,val,test)\n",
    "\n",
    "#         #target encoding on transaction merchant id\n",
    "#         tr,val,test = targetencode(tr, val,test,catcolnames,targetcol,\n",
    "#                                     smoothing,min_samples_leaf,noise_level)\n",
    "\n",
    "        tr,val,test = encode_target_cv(tr.reset_index(drop=True), val.reset_index(drop=True), \n",
    "                                       test.reset_index(drop=True), \n",
    "                                       targetcol, catcolnames,\n",
    "                                       n_folds=5, n_inner_folds=2\n",
    "                                      )\n",
    "\n",
    "        tr.index = tr_index\n",
    "        val.index = val_index\n",
    "        test.index = test_index\n",
    "\n",
    "        targetenccols = [col for col in tr.columns if 'targetenc' in col]\n",
    "        tr['targetenc_mean'] = tr[targetenccols].mean(axis=1)\n",
    "        val['targetenc_mean'] = val[targetenccols].mean(axis=1)        \n",
    "        test['targetenc_mean'] = test[targetenccols].mean(axis=1)        \n",
    "\n",
    "        tr['targetenc_std'] = tr[targetenccols].std(axis=1)\n",
    "        val['targetenc_std'] = val[targetenccols].std(axis=1)        \n",
    "        test['targetenc_std'] = test[targetenccols].std(axis=1) \n",
    "        \n",
    "        tr['targetenc_min'] = tr[targetenccols].min(axis=1)\n",
    "        val['targetenc_min'] = val[targetenccols].min(axis=1)        \n",
    "        test['targetenc_min'] = test[targetenccols].min(axis=1) \n",
    "        \n",
    "        tr['targetenc_max'] = tr[targetenccols].max(axis=1)\n",
    "        val['targetenc_max'] = val[targetenccols].max(axis=1)        \n",
    "        test['targetenc_max'] = test[targetenccols].max(axis=1) \n",
    "        \n",
    "        enc_cols = [col for col in tr.columns if 'targetenc' in col]\n",
    "        print('enc cols:',enc_cols)\n",
    "        print('save encoding feats...')\n",
    "\n",
    "        #save target encoding features in separate file\n",
    "        tr[enc_cols].to_csv('train_targetenc_feats'+str(fold_)+'.csv')\n",
    "        val[enc_cols].to_csv('val_targetenc_feats'+str(fold_)+'.csv')\n",
    "        test[enc_cols].to_csv('test_targetenc_feats'+str(fold_)+'.csv')\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    print('Target Enc Execution Time:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #generate group column for target encoding\n",
    "# for df in [train,test]:\n",
    "#     df['groupcol'] = df['resort_id'].astype('str').str.cat([df['persontravellingid'].astype('str'),\n",
    "#                             df['main_product_code'].astype('str'),\n",
    "#                             df['room_type_booked_code'].astype('str'),\n",
    "#                             df['state_code_residence'].astype('str')],\n",
    "#                             sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train['groupcol'].nunique())\n",
    "# print(test['groupcol'].nunique())\n",
    "\n",
    "# test_val = test['groupcol'].unique()\n",
    "# train_val = train['groupcol'].unique()\n",
    "\n",
    "# test_m_train = set(test_val).difference(train_val)\n",
    "# print(len(test_m_train))\n",
    "# print(test[test['groupcol'].isin(list(test_m_train))].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=train['groupcol'].value_counts()\n",
    "# print(temp.head(10))\n",
    "# print(temp.tail(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# catcolnames= ['groupcol']\n",
    "# # catcolnames= ['resort_id', 'state_code_residence','state_code_resort']\n",
    "# # othercatcols =['channel_code','main_product_code','resort_region_code',\n",
    "# #               'resort_type_code','room_type_booked_code','season_holidayed_code',\n",
    "# #               'member_age_buckets','cluster_code','reservationstatusid_code']\n",
    "# # catcolnames +=othercatcols\n",
    "# gen_targetencode(train,target,test,n_splits,catcolnames,targetcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getenc():\n",
    "    tr_encs = []\n",
    "    val_encs = []\n",
    "    test_encs = []\n",
    "    \n",
    "    Path=''\n",
    "\n",
    "    for i in range(0,5):\n",
    "        cur_tr_enc = pd.read_csv(Path+'train_targetenc_feats'+str(i)+'.csv',index_col=0)\n",
    "        cur_val_enc = pd.read_csv(Path+'val_targetenc_feats'+str(i)+'.csv',index_col=0)\n",
    "\n",
    "        tr_encs += [cur_tr_enc]\n",
    "        val_encs +=[ cur_val_enc]\n",
    "\n",
    "        test_encs += [pd.read_csv(Path+'test_targetenc_feats'+str(i)+'.csv',index_col=0)]\n",
    "        print('read complete for:',i)\n",
    "        \n",
    "    return tr_encs,val_encs,test_encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_encs, val_encs,test_encs = getenc()\n",
    "# print(tr_encs[0].shape)\n",
    "# print(val_encs[0].shape)\n",
    "# print(test_encs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runlgb(train,test,target,param,cur_features):\n",
    "\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    start = time.time()\n",
    "    valid_scores =[]\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    \n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=4590)\n",
    "    indices =  folds.split(train.values,target.values)   \n",
    "        \n",
    "#     folds = GroupKFold(n_splits=n_splits)\n",
    "#     indices =  folds.split(train.values,target.values,train['memberid'].values)   \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(indices):\n",
    "        print()\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "\n",
    "        tr = train.iloc[trn_idx]\n",
    "        val = train.iloc[val_idx]\n",
    "        y_val = target.iloc[val_idx]\n",
    "        y_tr = target.iloc[trn_idx]\n",
    "        \n",
    "        test_cur = test.copy()\n",
    "        \n",
    "        \n",
    "#         cur_tr_encs = tr_encs[fold_]\n",
    "#         cur_val_encs= val_encs[fold_]\n",
    "\n",
    "#         print('val shape bef:',val.shape)\n",
    "#         print('tr shape bef:',tr.shape)\n",
    "#         print('test shape bef:',test.shape)\n",
    "        \n",
    "#         tr=pd.concat([tr,cur_tr_encs],axis=1)\n",
    "#         val=pd.concat([val,cur_val_encs],axis=1)\n",
    "#         test_cur=pd.concat([test,test_encs[fold_]],axis=1)\n",
    "                \n",
    "#         print('val shape after:',val.shape)\n",
    "#         print('tr shape after:',tr.shape)\n",
    "#         print('test shape after:',test.shape)    \n",
    "        \n",
    "        \n",
    "        trn_data = lgb.Dataset(tr[cur_features], label=y_tr)#,, categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(val[cur_features], label=y_val)#,, categorical_feature=categorical_feats)\n",
    "        \n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], \n",
    "                        verbose_eval=500, early_stopping_rounds = 200)\n",
    "\n",
    "        #Prediction based on current fold selected features\n",
    "        oof[val_idx] = clf.predict(val[cur_features], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        fold_importance_df[\"feature\"] = cur_features\n",
    "        if fold_==0:\n",
    "            fold_importance_df[\"importance\"] =0\n",
    "        fold_importance_df[\"importance\"] += clf.feature_importance() / n_splits\n",
    "        valid_scores+=[clf.best_score['valid_0'][param['metric']]]\n",
    "        predictions += clf.predict(test_cur[cur_features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print('valid scores:',valid_scores)\n",
    "    print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))\n",
    "    \n",
    "    return fold_importance_df,predictions,oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'objective':'regression',\n",
    "#          'num_leaves': 31,\n",
    "#          'min_data_in_leaf': 25,\n",
    "#          'max_depth': 7,\n",
    "#          'learning_rate': 0.01,\n",
    "#          'lambda_l1':0.13,\n",
    "#          \"boosting\": \"gbdt\",\n",
    "#          \"feature_fraction\":0.85,\n",
    "#          'bagging_freq':8,\n",
    "#          \"bagging_fraction\": 0.9 ,\n",
    "#          \"metric\": 'rmse',\n",
    "#          \"verbosity\": -1,\n",
    "#          'n_estimators': 10000,\n",
    "#          \"random_state\": 2333}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'colsample_bytree': 0.7435507072475522,\n",
    "#    'min_child_samples': 200,\n",
    "#    'num_leaves': 33,\n",
    "#    'reg_alpha': 0.30232162973796833,\n",
    "#    'reg_lambda': 0.2679669294245453,\n",
    "#    'subsample': 0.807559171733078,\n",
    "#    'subsample_for_bin': 130000,\n",
    "#    'learning_rate': 0.01,\n",
    "#    'boosting': 'gbdt',\n",
    "#    'bagging_seed': 2018,\n",
    "#    'bagging_freq': 2,\n",
    "#    'min_data_in_bin': 100,\n",
    "#    'n_estimators': 10000,\n",
    "#    'objective': 'regression',\n",
    "#    'metric': 'rmse',\n",
    "#    'random_state': 2333,\n",
    "#    'max_depth': 15,\n",
    "#    'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'colsample_bytree': 0.6003677943112755,\n",
    "   'min_child_samples': 200,\n",
    "   'num_leaves': 37,\n",
    "   'reg_alpha': 0.4673020868826969,\n",
    "   'reg_lambda': 0.327996673259906,\n",
    "   'subsample': 0.9327220260448092,\n",
    "   'subsample_for_bin': 80000,\n",
    "   'learning_rate': 0.01,\n",
    "   'boosting': 'gbdt',\n",
    "   'bagging_seed': 2018,\n",
    "   'bagging_freq': 2,\n",
    "   'min_data_in_bin': 100,\n",
    "   'n_estimators': 10000,\n",
    "   'objective': 'regression',\n",
    "   'metric': 'rmse',\n",
    "   'random_state': 2333,\n",
    "   'max_depth': 15,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Model category cols\n",
    "# # cat_cols = ['booking_type_code', 'channel_code', 'cluster_code', 'main_product_code', \n",
    "# #             'member_age_buckets','persontravellingid', 'reservationstatusid_code', 'resort_id', \n",
    "# #             'resort_region_code', 'resort_type_code', 'room_type_booked_code',\n",
    "# #            'season_holidayed_code', 'state_code_residence', 'state_code_resort',\n",
    "# # #            'booking_month', 'booking_year'\n",
    "# #            ]\n",
    "\n",
    "# cat_cols = ['resort_id']\n",
    "\n",
    "# for col in cat_cols:\n",
    "#     for df in [train,test]:\n",
    "#         df[col]=df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['memberid'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_fewvisitmembers(col,data):\n",
    "    global_mean = data[col].mean()\n",
    "    data.loc[data['member_size']<=5,col]=global_mean\n",
    "#     data.loc[data['member_size']<=3,col]=np.nan\n",
    "    return data\n",
    "\n",
    "for df in [train,test]:\n",
    "    cur_df = df.sort_values(['checkin_date'])\n",
    "    df['member_repeat'] = cur_df.groupby(['memberid'])['checkin_date'].cumcount()\n",
    "    df['member_resort_repeat'] = cur_df.groupby(['memberid','resort_id'])['checkin_date'].cumcount()\n",
    "#     df['member_size'] = cur_df.groupby(['memberid'])['memberid'].transform('count')\n",
    "    \n",
    "    df['member_roomnights_mean'] = cur_df.groupby(['memberid'])['roomnights'].transform('mean')\n",
    "#     df['member_roomnights_std'] = cur_df.groupby(['memberid'])['roomnights'].transform('std')\n",
    "#     df['member_roomnights_min'] = cur_df.groupby(['memberid'])['roomnights'].transform('min')\n",
    "#     df['member_roomnights_max'] = cur_df.groupby(['memberid'])['roomnights'].transform('max')\n",
    "    df['member_resort_roomnights_mean'] = cur_df.groupby(['memberid','resort_id'])['roomnights'].transform('mean')\n",
    "    \n",
    "    df['member_numberofadults_mean'] = cur_df.groupby(['memberid'])['numberofadults'].transform('mean')\n",
    "#     df['member_numberofadults_std'] = cur_df.groupby(['memberid'])['numberofadults'].transform('std')\n",
    "#     df['member_numberofadults_min'] = cur_df.groupby(['memberid'])['numberofadults'].transform('min')\n",
    "#     df['member_numberofadults_max'] = cur_df.groupby(['memberid'])['numberofadults'].transform('max')\n",
    "    df['member_resort_numberofadults_mean'] = cur_df.groupby(['memberid','resort_id'])['numberofadults'].transform('mean')\n",
    "    \n",
    "    df['member_total_pax_mean'] = cur_df.groupby(['memberid'])['total_pax'].transform('mean')\n",
    "#     df['member_total_pax_std'] = cur_df.groupby(['memberid'])['total_pax'].transform('std')\n",
    "#     df['member_total_pax_min'] = cur_df.groupby(['memberid'])['total_pax'].transform('min')\n",
    "#     df['member_total_pax_max'] = cur_df.groupby(['memberid'])['total_pax'].transform('max')\n",
    "    df['member_resort_total_pax_mean'] = cur_df.groupby(['memberid','resort_id'])['total_pax'].transform('mean')\n",
    "#     df['state_same'] = (df['state_code_residence']==df['state_code_resort']).astype('int')\n",
    "\n",
    "#     df =fill_fewvisitmembers('member_roomnights_std',df)\n",
    "#     df =fill_fewvisitmembers('member_numberofadults_std',df)\n",
    "#     df =fill_fewvisitmembers('member_total_pax_std',df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train['member_size'].describe())\n",
    "# print(train['member_roomnights_std'].describe())\n",
    "# # print(train['member_roomnights_std'].describe())\n",
    "# # global_mean = train['member_roomnights_std'].mean()\n",
    "# # print('global mean shape:',train[train['member_roomnights_std']==global_mean].shape)\n",
    "\n",
    "# # print(train[train['member_roomnights_std'].isnull()].shape)\n",
    "# print(train.loc[train['member_size']==1,'member_roomnights_std'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[['memberid','member_roomnights_mean','roomnights','member_resort_roomnights_mean','resort_id']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of features: 38\n",
      "\n",
      "['booking_type_code', 'channel_code', 'cluster_code', 'main_product_code', 'member_age_buckets', 'numberofadults', 'numberofchildren', 'persontravellingid', 'reservationstatusid_code', 'resort_id', 'resort_region_code', 'resort_type_code', 'room_type_booked_code', 'roomnights', 'season_holidayed_code', 'state_code_residence', 'state_code_resort', 'total_pax', 'checkin_month', 'checkin_year', 'checkin_dayofweek', 'checkin_weekend', 'checkout_month', 'checkout_year', 'checkout_dayofweek', 'checkout_weekend', 'booking_month', 'booking_year', 'booking_dayofweek', 'booking_weekend', 'member_repeat', 'member_resort_repeat', 'member_roomnights_mean', 'member_resort_roomnights_mean', 'member_numberofadults_mean', 'member_resort_numberofadults_mean', 'member_total_pax_mean', 'member_resort_total_pax_mean']\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['reservation_id','memberid',\n",
    "               'booking_date', 'checkin_date', 'checkout_date',\n",
    "                'groupcol',\n",
    "                'group_count',\n",
    "                'state_same',\n",
    "                'member_roomnights_std','member_numberofadults_std','member_total_pax_std',\n",
    "                'member_size',\n",
    "               targetcol]\n",
    "# ohe_cols =['channel_code','main_product_code','resort_region_code',\n",
    "#               'resort_type_code','room_type_booked_code','season_holidayed_code',\n",
    "#               'member_age_buckets','cluster_code','reservationstatusid_code']\n",
    "# exclude_cols += ohe_cols\n",
    "\n",
    "# targetenccols  = [col for col in tr_encs[0].columns]\n",
    "features = [col for col in train.columns if col not in exclude_cols]\n",
    "# features += ['targetenc_groupcol']\n",
    "# features += ['targetenc_mean','targetenc_std','targetenc_min','targetenc_max']\n",
    "print('Length of features:',len(features))\n",
    "print()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_feats = features.copy()\n",
    "# corr_feats +=[targetcol]\n",
    "# corr_feats.remove('targetenc_groupcol')\n",
    "# train[corr_feats].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\tvalid_0's rmse: 1.01213\n",
      "[1000]\tvalid_0's rmse: 0.995839\n",
      "[1500]\tvalid_0's rmse: 0.990182\n",
      "[2000]\tvalid_0's rmse: 0.987472\n",
      "[2500]\tvalid_0's rmse: 0.985744\n",
      "[3000]\tvalid_0's rmse: 0.984387\n",
      "[3500]\tvalid_0's rmse: 0.983302\n",
      "[4000]\tvalid_0's rmse: 0.982511\n",
      "[4500]\tvalid_0's rmse: 0.981959\n",
      "[5000]\tvalid_0's rmse: 0.98152\n",
      "[5500]\tvalid_0's rmse: 0.981319\n",
      "[6000]\tvalid_0's rmse: 0.981163\n",
      "[6500]\tvalid_0's rmse: 0.980921\n",
      "[7000]\tvalid_0's rmse: 0.980738\n",
      "[7500]\tvalid_0's rmse: 0.980642\n",
      "[8000]\tvalid_0's rmse: 0.980564\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7987]\tvalid_0's rmse: 0.980562\n",
      "\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\tvalid_0's rmse: 1.01457\n",
      "[1000]\tvalid_0's rmse: 0.996124\n",
      "[1500]\tvalid_0's rmse: 0.990772\n",
      "[2000]\tvalid_0's rmse: 0.988042\n",
      "[2500]\tvalid_0's rmse: 0.986613\n",
      "[3000]\tvalid_0's rmse: 0.985663\n",
      "[3500]\tvalid_0's rmse: 0.984747\n",
      "[4000]\tvalid_0's rmse: 0.983986\n",
      "[4500]\tvalid_0's rmse: 0.983447\n",
      "[5000]\tvalid_0's rmse: 0.98314\n",
      "[5500]\tvalid_0's rmse: 0.982882\n",
      "[6000]\tvalid_0's rmse: 0.982603\n",
      "[6500]\tvalid_0's rmse: 0.982469\n",
      "[7000]\tvalid_0's rmse: 0.982362\n",
      "[7500]\tvalid_0's rmse: 0.982246\n",
      "[8000]\tvalid_0's rmse: 0.98211\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7986]\tvalid_0's rmse: 0.982105\n",
      "\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\tvalid_0's rmse: 0.997121\n",
      "[1000]\tvalid_0's rmse: 0.980382\n",
      "[1500]\tvalid_0's rmse: 0.975237\n",
      "[2000]\tvalid_0's rmse: 0.972578\n",
      "[2500]\tvalid_0's rmse: 0.971007\n",
      "[3000]\tvalid_0's rmse: 0.969946\n",
      "[3500]\tvalid_0's rmse: 0.969261\n",
      "[4000]\tvalid_0's rmse: 0.968635\n",
      "[4500]\tvalid_0's rmse: 0.968294\n",
      "[5000]\tvalid_0's rmse: 0.967997\n",
      "[5500]\tvalid_0's rmse: 0.96775\n",
      "[6000]\tvalid_0's rmse: 0.967618\n",
      "[6500]\tvalid_0's rmse: 0.967473\n",
      "[7000]\tvalid_0's rmse: 0.967413\n",
      "[7500]\tvalid_0's rmse: 0.967376\n",
      "[8000]\tvalid_0's rmse: 0.9673\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7998]\tvalid_0's rmse: 0.9673\n",
      "\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\tvalid_0's rmse: 1.01203\n",
      "[1000]\tvalid_0's rmse: 0.993339\n",
      "[1500]\tvalid_0's rmse: 0.986992\n",
      "[2000]\tvalid_0's rmse: 0.984262\n",
      "[2500]\tvalid_0's rmse: 0.982425\n",
      "[3000]\tvalid_0's rmse: 0.981271\n",
      "[3500]\tvalid_0's rmse: 0.980413\n",
      "[4000]\tvalid_0's rmse: 0.97986\n",
      "[4500]\tvalid_0's rmse: 0.979354\n",
      "[5000]\tvalid_0's rmse: 0.978958\n",
      "[5500]\tvalid_0's rmse: 0.978659\n",
      "[6000]\tvalid_0's rmse: 0.978543\n",
      "[6500]\tvalid_0's rmse: 0.978429\n",
      "[7000]\tvalid_0's rmse: 0.978289\n",
      "[7500]\tvalid_0's rmse: 0.978137\n",
      "[8000]\tvalid_0's rmse: 0.978119\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7931]\tvalid_0's rmse: 0.978095\n",
      "\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\tvalid_0's rmse: 0.997757\n",
      "[1000]\tvalid_0's rmse: 0.980093\n",
      "[1500]\tvalid_0's rmse: 0.974706\n",
      "[2000]\tvalid_0's rmse: 0.971727\n",
      "[2500]\tvalid_0's rmse: 0.969679\n",
      "[3000]\tvalid_0's rmse: 0.968301\n",
      "[3500]\tvalid_0's rmse: 0.967243\n",
      "[4000]\tvalid_0's rmse: 0.966529\n",
      "[4500]\tvalid_0's rmse: 0.966098\n",
      "[5000]\tvalid_0's rmse: 0.965661\n",
      "[5500]\tvalid_0's rmse: 0.965331\n",
      "[6000]\tvalid_0's rmse: 0.965073\n",
      "[6500]\tvalid_0's rmse: 0.964896\n",
      "[7000]\tvalid_0's rmse: 0.964759\n",
      "[7500]\tvalid_0's rmse: 0.964652\n",
      "[8000]\tvalid_0's rmse: 0.964586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7928]\tvalid_0's rmse: 0.964564\n",
      "valid scores: [0.9805619574218503, 0.9821053765290509, 0.9673002862822552, 0.9780952516942039, 0.9645638885157206]\n",
      "CV score: 0.97455 \n",
      "CPU times: user 1h 38min 56s, sys: 1min 21s, total: 1h 40min 17s\n",
      "Wall time: 25min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_splits=5\n",
    "param['n_estimators']= 8000\n",
    "num_round = param['n_estimators']\n",
    "fold_importance_df,predictions,oof = runlgb(train,test,target,param,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>booking_dayofweek</td>\n",
       "      <td>7469.0</td>\n",
       "      <td>0.026052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>booking_month</td>\n",
       "      <td>9158.4</td>\n",
       "      <td>0.031944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>booking_type_code</td>\n",
       "      <td>1145.8</td>\n",
       "      <td>0.003996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>booking_weekend</td>\n",
       "      <td>413.8</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>booking_year</td>\n",
       "      <td>4442.4</td>\n",
       "      <td>0.015495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>channel_code</td>\n",
       "      <td>4821.6</td>\n",
       "      <td>0.016818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>checkin_dayofweek</td>\n",
       "      <td>10899.8</td>\n",
       "      <td>0.038018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>checkin_month</td>\n",
       "      <td>7770.2</td>\n",
       "      <td>0.027102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>checkin_weekend</td>\n",
       "      <td>661.2</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>checkin_year</td>\n",
       "      <td>4183.8</td>\n",
       "      <td>0.014593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>checkout_dayofweek</td>\n",
       "      <td>10548.2</td>\n",
       "      <td>0.036792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>checkout_month</td>\n",
       "      <td>7423.4</td>\n",
       "      <td>0.025892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>checkout_weekend</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>checkout_year</td>\n",
       "      <td>3653.8</td>\n",
       "      <td>0.012744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cluster_code</td>\n",
       "      <td>5613.6</td>\n",
       "      <td>0.019580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main_product_code</td>\n",
       "      <td>4800.8</td>\n",
       "      <td>0.016745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>member_age_buckets</td>\n",
       "      <td>9692.4</td>\n",
       "      <td>0.033807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>member_numberofadults_mean</td>\n",
       "      <td>21897.8</td>\n",
       "      <td>0.076378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>member_repeat</td>\n",
       "      <td>8290.6</td>\n",
       "      <td>0.028917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>member_resort_numberofadults_mean</td>\n",
       "      <td>9385.0</td>\n",
       "      <td>0.032734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>member_resort_repeat</td>\n",
       "      <td>3787.2</td>\n",
       "      <td>0.013210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>member_resort_roomnights_mean</td>\n",
       "      <td>13112.2</td>\n",
       "      <td>0.045735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>member_resort_total_pax_mean</td>\n",
       "      <td>8435.2</td>\n",
       "      <td>0.029422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>member_roomnights_mean</td>\n",
       "      <td>23532.4</td>\n",
       "      <td>0.082080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>member_total_pax_mean</td>\n",
       "      <td>18598.6</td>\n",
       "      <td>0.064871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>numberofadults</td>\n",
       "      <td>7179.4</td>\n",
       "      <td>0.025041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>numberofchildren</td>\n",
       "      <td>3004.4</td>\n",
       "      <td>0.010479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>persontravellingid</td>\n",
       "      <td>4558.6</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reservationstatusid_code</td>\n",
       "      <td>773.2</td>\n",
       "      <td>0.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resort_id</td>\n",
       "      <td>15775.8</td>\n",
       "      <td>0.055025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resort_region_code</td>\n",
       "      <td>3066.4</td>\n",
       "      <td>0.010695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resort_type_code</td>\n",
       "      <td>5005.6</td>\n",
       "      <td>0.017459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>room_type_booked_code</td>\n",
       "      <td>4681.0</td>\n",
       "      <td>0.016327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>roomnights</td>\n",
       "      <td>10301.2</td>\n",
       "      <td>0.035930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>season_holidayed_code</td>\n",
       "      <td>4617.6</td>\n",
       "      <td>0.016106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>state_code_residence</td>\n",
       "      <td>13624.2</td>\n",
       "      <td>0.047521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>state_code_resort</td>\n",
       "      <td>8513.2</td>\n",
       "      <td>0.029694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>total_pax</td>\n",
       "      <td>5126.4</td>\n",
       "      <td>0.017881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance     ratio\n",
       "28                  booking_dayofweek      7469.0  0.026052\n",
       "26                      booking_month      9158.4  0.031944\n",
       "0                   booking_type_code      1145.8  0.003996\n",
       "29                    booking_weekend       413.8  0.001443\n",
       "27                       booking_year      4442.4  0.015495\n",
       "1                        channel_code      4821.6  0.016818\n",
       "20                  checkin_dayofweek     10899.8  0.038018\n",
       "18                      checkin_month      7770.2  0.027102\n",
       "21                    checkin_weekend       661.2  0.002306\n",
       "19                       checkin_year      4183.8  0.014593\n",
       "24                 checkout_dayofweek     10548.2  0.036792\n",
       "22                     checkout_month      7423.4  0.025892\n",
       "25                   checkout_weekend       737.0  0.002571\n",
       "23                      checkout_year      3653.8  0.012744\n",
       "2                        cluster_code      5613.6  0.019580\n",
       "3                   main_product_code      4800.8  0.016745\n",
       "4                  member_age_buckets      9692.4  0.033807\n",
       "34         member_numberofadults_mean     21897.8  0.076378\n",
       "30                      member_repeat      8290.6  0.028917\n",
       "35  member_resort_numberofadults_mean      9385.0  0.032734\n",
       "31               member_resort_repeat      3787.2  0.013210\n",
       "33      member_resort_roomnights_mean     13112.2  0.045735\n",
       "37       member_resort_total_pax_mean      8435.2  0.029422\n",
       "32             member_roomnights_mean     23532.4  0.082080\n",
       "36              member_total_pax_mean     18598.6  0.064871\n",
       "5                      numberofadults      7179.4  0.025041\n",
       "6                    numberofchildren      3004.4  0.010479\n",
       "7                  persontravellingid      4558.6  0.015900\n",
       "8            reservationstatusid_code       773.2  0.002697\n",
       "9                           resort_id     15775.8  0.055025\n",
       "10                 resort_region_code      3066.4  0.010695\n",
       "11                   resort_type_code      5005.6  0.017459\n",
       "12              room_type_booked_code      4681.0  0.016327\n",
       "13                         roomnights     10301.2  0.035930\n",
       "14              season_holidayed_code      4617.6  0.016106\n",
       "15               state_code_residence     13624.2  0.047521\n",
       "16                  state_code_resort      8513.2  0.029694\n",
       "17                          total_pax      5126.4  0.017881"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_importance_df['ratio'] = fold_importance_df['importance'] / fold_importance_df['importance'].sum()\n",
    "fold_importance_df.sort_values('feature',ascending=True,inplace=True)\n",
    "# fold_importance_df.sort_index(inplace=True)\n",
    "\n",
    "# fold_importance_df.sort_values('importance',ascending=False,inplace=True)\n",
    "fold_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"reservation_id\":test[\"reservation_id\"].values})\n",
    "sub_df[targetcol] = predictions\n",
    "sub_df.to_csv(\"submission_membergroupcount.csv\", index=False)\n",
    "np.save('oof_membergroupcount.npy',oof)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
